{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19c9e244-3643-4e66-a7ab-b5dd6a50cc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping terminé. Données sauvegardées dans products_selenium.json\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import json\n",
    "\n",
    "categories_to_search = ['womens sport', 'bags', \n",
    "                        'fragrances', 'nails', \n",
    "                        'sunglasses', 'dresses', \n",
    "                        'jewellery', 'womens+shoes', \n",
    "                        'womens+watches']\n",
    "products = []\n",
    "item = 1\n",
    "\n",
    "# Configurer Selenium pour utiliser Chrome\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")  # Utiliser le mode sans tête (sans interface graphique)\n",
    "options.add_argument(\"--disable-gpu\")  # Désactiver le GPU pour éviter des erreurs\n",
    "options.add_argument(\"--no-sandbox\")  # Désactiver le sandbox pour éviter des erreurs\n",
    "\n",
    "# Démarrer le navigateur Selenium\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "for category in categories_to_search:\n",
    "    URL = f\"https://www.amazon.com/s?k={category}+products\"\n",
    "    \n",
    "    # Accéder à la page\n",
    "    driver.get(URL)\n",
    "    \n",
    "    # Attendre que la page se charge complètement (ajuster le temps si nécessaire)\n",
    "    time.sleep(5)  # Attendre 5 secondes\n",
    "    \n",
    "    # Récupérer le contenu de la page après le rendu dynamique par JavaScript\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    \n",
    "    # Extraire les détails des produits\n",
    "    for product in soup.find_all(\"div\", {\"data-component-type\": \"s-search-result\"}):\n",
    "        try:\n",
    "            # Titre\n",
    "            title = product.h2.text.strip() if product.h2 else \"N/A\"\n",
    "            \n",
    "            # Description (Amazon souvent avec une description d'image)\n",
    "            description_tag = product.find(\"img\", class_=\"s-image\")\n",
    "            description = description_tag[\"alt\"] if description_tag else \"N/A\"\n",
    "            \n",
    "            # Prix\n",
    "            price_whole = product.find(\"span\", class_=\"a-price-whole\")\n",
    "            price_fraction = product.find(\"span\", class_=\"a-price-fraction\")\n",
    "            if price_whole and price_fraction:\n",
    "                price = f\"{price_whole.text.strip()}.{price_fraction.text.strip()}\"\n",
    "            else:\n",
    "                price = \"N/A\"\n",
    "            \n",
    "            # Évaluation\n",
    "            rating_tag = product.find(\"span\", class_=\"a-icon-alt\")\n",
    "            rating = rating_tag.text.strip() if rating_tag else \"N/A\"\n",
    "            \n",
    "            # Stock\n",
    "            stock = \"Available\" if product.find(\"span\", {\"class\": \"a-color-price\"}) else \"UnAvailable\"\n",
    "            \n",
    "            # Image\n",
    "            image_tag = product.find(\"img\", class_=\"s-image\")\n",
    "            image_url = image_tag[\"src\"] if image_tag else \"N/A\"\n",
    "\n",
    "            products.append({\n",
    "                \"id\": item,\n",
    "                \"title\": title,\n",
    "                \"description\": description,\n",
    "                \"category\": category,\n",
    "                \"price\": price,\n",
    "                \"rating\": rating,\n",
    "                \"stock\": stock,\n",
    "                \"image\": image_url,\n",
    "                \"reviews\": []\n",
    "            })\n",
    "            item += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de l'extraction du produit : {e}\")\n",
    "    \n",
    "    # Attendre avant de passer à la prochaine catégorie\n",
    "    time.sleep(10)  # Attendre 10 secondes entre les requêtes\n",
    "\n",
    "# Fermer le navigateur Selenium après l'exécution\n",
    "driver.quit()\n",
    "\n",
    "# Sauvegarder les données dans un fichier JSON\n",
    "with open(\"products_selenium.json\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "    json.dump(products, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"Scraping terminé. Données sauvegardées dans products_selenium.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb7c630-cb27-4e64-a4df-4c66b041b5c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
